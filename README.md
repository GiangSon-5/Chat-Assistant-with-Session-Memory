# Chat Assistant Backend with Session Memory

Dá»± Ã¡n nÃ y lÃ  má»™t báº£n demo ká»¹ thuáº­t (Technical Demo) xÃ¢y dá»±ng backend cho má»™t Chat Assistant thÃ´ng minh. Há»‡ thá»‘ng táº­p trung vÃ o hai tÃ­nh nÄƒng cá»‘t lÃµi: **Session Memory (Bá»™ nhá»› ngáº¯n háº¡n qua tÃ³m táº¯t tá»± Ä‘á»™ng)** vÃ  **Query Understanding Pipeline (ÄÆ°á»ng á»‘ng xá»­ lÃ½ vÃ  lÃ m rÃµ Ã½ Ä‘á»‹nh ngÆ°á»i dÃ¹ng)**.

Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ theo kiáº¿n trÃºc tÃ¡ch biá»‡t Client-Server, sá»­ dá»¥ng mÃ´ hÃ¬nh **Llama-3-8B-Instruct** vÃ  tuÃ¢n thá»§ cháº·t cháº½ viá»‡c kiá»ƒm soÃ¡t Ä‘áº§u ra báº±ng **Structured Outputs (Pydantic Schema)**.

<p align="center">
  <img src="/imgs/flow.png" alt="Pipeline Flow" width="100%"/>
</p>


---

## ğŸ› ï¸ YÃªu cáº§u há»‡ thá»‘ng

Há»‡ thá»‘ng hoáº¡t Ä‘á»™ng theo mÃ´ hÃ¬nh Client-Server:

1. **Server (Backend Model):** Cháº¡y trÃªn mÃ´i trÆ°á»ng cÃ³ GPU (Google Colab A100) Ä‘á»ƒ host Llama-3 qua FastAPI.
2. **Client (Application):** Cháº¡y trÃªn mÃ¡y cÃ¡ nhÃ¢n (Localhost), sá»­ dá»¥ng Python 3.11 vÃ  Streamlit.

---

## ğŸš€ HÆ°á»›ng dáº«n CÃ i Ä‘áº·t & Thiáº¿t láº­p

### 1. Chuáº©n bá»‹ Server (Google Colab)

MÃ´ hÃ¬nh Llama-3-8B yÃªu cáº§u GPU â€” thÆ°á»ng cháº¡y trÃªn Google Colab vÃ  Ä‘Æ°á»£c expose báº±ng `ngrok`. Náº¿u báº¡n cÃ³ template Colab, dÃ¹ng nÃ³; náº¿u khÃ´ng, báº¡n cÃ³ hai lá»±a chá»n:

- Cháº¡y má»™t server LLM cÃ³ sáºµn vÃ  Ä‘áº·t `LLM_API_BASE_URL` tá»›i endpoint Ä‘Ã³.

Náº¿u báº¡n sá»­ dá»¥ng Colab, nhá»¯ng bÆ°á»›c chÃ­nh lÃ :

1. Táº¡o Notebook má»›i trÃªn Colab vÃ  chá»n Runtime â†’ GPU (A100 náº¿u cÃ³).
2. ThÃªm cÃ¡c biáº¿n/secret cáº§n thiáº¿t vÃ o notebook (vÃ­ dá»¥ `HF_TOKEN`, `NGROK_TOKEN`) vÃ  khá»Ÿi cháº¡y server.

> Hoáº·c dÃ¹ng API cá»§a báº¡n (xem `Config.LLM_API_BASE_URL`) â€” Streamlit client sáº½ káº¿t ná»‘i tá»›i URL Ä‘Ã³.

5. Cháº¡y cell. Khi server khá»Ÿi Ä‘á»™ng thÃ nh cÃ´ng, báº¡n sáº½ nháº­n Ä‘Æ°á»£c má»™t URL dáº¡ng:

```text
ğŸš€ API BASE URL: https://xxxx-xx-xx-xx-xx.ngrok-free.app/v1

```

_LÆ°u láº¡i URL nÃ y Ä‘á»ƒ cáº¥u hÃ¬nh á»Ÿ bÆ°á»›c sau._

### 2. CÃ i Ä‘áº·t Client (Local Machine)

**BÆ°á»›c 1: Clone dá»± Ã¡n vÃ  táº¡o mÃ´i trÆ°á»ng áº£o**
Khuyáº¿n nghá»‹ sá»­ dá»¥ng **Python 3.11**.

```bash
# Táº¡o mÃ´i trÆ°á»ng áº£o
python -m venv venv

# KÃ­ch hoáº¡t mÃ´i trÆ°á»ng (Windows)
venv\Scripts\activate

# KÃ­ch hoáº¡t mÃ´i trÆ°á»ng (Mac/Linux)
source venv/bin/activate

```

**BÆ°á»›c 2: CÃ i Ä‘áº·t thÆ° viá»‡n**

```bash
pip install -r requirements.txt

```

**BÆ°á»›c 3: Cáº¥u hÃ¬nh biáº¿n mÃ´i trÆ°á»ng**
Táº¡o file `.env` táº¡i thÆ° má»¥c gá»‘c.

VÃ­ dá»¥ tá»‘i thiá»ƒu cá»§a `.env` (thay `...` báº±ng giÃ¡ trá»‹ thá»±c):

```ini
LLM_API_BASE_URL=https://xxxx-xx-xx-xx-xx.ngrok-free.app/v1
MEMORY_THRESHOLD_TOKENS=200
```



---

## ğŸƒâ€â™‚ï¸ CÃ¡ch cháº¡y Demo

Sau khi server Colab Ä‘Ã£ cháº¡y vÃ  file `.env` Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh, báº¡n khá»Ÿi Ä‘á»™ng giao diá»‡n Streamlit báº±ng lá»‡nh:

```bash
streamlit run demo/streamlit_app.py

```

á»¨ng dá»¥ng sáº½ tá»± Ä‘á»™ng má»Ÿ táº¡i `http://localhost:8501`.

---

## ğŸ§ª CÃ¡c bÆ°á»›c kiá»ƒm thá»­ (Testing Flows)

Dá»± Ã¡n Ä‘i kÃ¨m vá»›i dá»¯ liá»‡u test trong thÆ° má»¥c `tests/test_data/` Ä‘á»ƒ kiá»ƒm chá»©ng cÃ¡c tÃ­nh nÄƒng cá»‘t lÃµi.

### Flow 1: Kiá»ƒm thá»­ Session Memory (Tá»± Ä‘á»™ng tÃ³m táº¯t)

**Má»¥c tiÃªu:** Chá»©ng minh há»‡ thá»‘ng tá»± Ä‘á»™ng tÃ³m táº¯t há»™i thoáº¡i khi vÆ°á»£t quÃ¡ giá»›i háº¡n token.

1. TrÃªn giao diá»‡n Streamlit, nhÃ¬n vÃ o Sidebar bÃªn trÃ¡i.
2. Äiá»u chá»‰nh thanh trÆ°á»£t **Memory Threshold** xuá»‘ng tháº¥p (vÃ­ dá»¥: `200` tokens).
3. Nháº¥n nÃºt **"Load Long Conversation (Trigger Memory)"**.
4. **Káº¿t quáº£ mong Ä‘á»£i:**

- Há»‡ thá»‘ng táº£i Ä‘oáº¡n há»™i thoáº¡i dÃ i tá»« file `tests/test_data/long_conversation.jsonl`.
- Token counter (hiá»ƒn thá»‹ trong tab "Pipeline Visualizer" hoáº·c Log) sáº½ vÆ°á»£t ngÆ°á»¡ng.
- Má»™t thÃ´ng bÃ¡o "Summarization Triggered!" xuáº¥t hiá»‡n.
- Chuyá»ƒn sang tab **"ğŸ’¾ Memory & State"**, báº¡n sáº½ tháº¥y JSON tÃ³m táº¯t (UserProfile, Key Facts, v.v.).

### Flow 2: Kiá»ƒm thá»­ Query Understanding (Xá»­ lÃ½ cÃ¢u há»i mÆ¡ há»“)

**Má»¥c tiÃªu:** Chá»©ng minh há»‡ thá»‘ng phÃ¡t hiá»‡n cÃ¢u há»i khÃ´ng rÃµ rÃ ng vÃ  tá»± Ä‘á»™ng viáº¿t láº¡i.

1. Má»Ÿ file `tests/test_data/test_queries.md` Ä‘á»ƒ xem vÃ­ dá»¥, hoáº·c nháº­p trá»±c tiáº¿p vÃ o khung chat.
2. Má»Ÿ tab **"ğŸ› ï¸ Pipeline Visualizer"** (hoáº·c xem log ngay trÃªn khung chat).
3. **Káº¿t quáº£ mong Ä‘á»£i:**

- Step "Query Analysis" hiá»ƒn thá»‹ JSON.
- `is_ambiguous`: `true`.
- Há»‡ thá»‘ng tráº£ lá»i dá»±a trÃªn cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c viáº¿t láº¡i.

---

## ğŸ“‚ Giáº£i thÃ­ch Cáº¥u trÃºc Dá»± Ã¡n

Dá»± Ã¡n Ä‘Æ°á»£c tá»• chá»©c theo cáº¥u trÃºc module hÃ³a, tÃ¡ch biá»‡t rÃµ rÃ ng giá»¯a logic nghiá»‡p vá»¥ (Business Logic) vÃ  giao diá»‡n (UI).

```text
chat-assistant-backend/
â”œâ”€â”€ src/                        # SOURCE CODE CHÃNH
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py               # Quáº£n lÃ½ cáº¥u hÃ¬nh (Load biáº¿n mÃ´i trÆ°á»ng, Ä‘Æ°á»ng dáº«n file).
â”‚   â”œâ”€â”€ models.py               # Pydantic Schemas. Äá»‹nh nghÄ©a cáº¥u trÃºc dá»¯ liá»‡u input/output (Validation).
â”‚   â”œâ”€â”€ session_memory.py       # CORE FEATURE A. Logic quáº£n lÃ½ bá»™ nhá»› vÃ  kÃ­ch hoáº¡t tÃ³m táº¯t (Summarization).
â”‚   â”œâ”€â”€ query_processor.py      # CORE FEATURE B. Pipeline xá»­ lÃ½ cÃ¢u há»i: Ambiguity check -> Rewrite -> Augment.
â”‚   â”œâ”€â”€ token_counter.py        # Tiá»‡n Ã­ch Ä‘áº¿m token (sá»­ dá»¥ng tiktoken).
â”‚   â”œâ”€â”€ llm_client.py           # Client giao tiáº¿p vá»›i API Server (Llama-3). Xá»­ lÃ½ request/response.
â”‚   â””â”€â”€ storage.py              # Quáº£n lÃ½ File I/O (LÆ°u/Äá»c session memory vÃ  test data).
â”‚
â”œâ”€â”€ demo/
â”‚   â””â”€â”€ streamlit_app.py        # Giao diá»‡n ngÆ°á»i dÃ¹ng (UI). Káº¿t ná»‘i cÃ¡c module trong /src Ä‘á»ƒ demo flow.
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sessions/               # ThÆ° má»¥c chá»©a file bá»™ nhá»› phiÃªn lÃ m viá»‡c (Ä‘Æ°á»£c táº¡o ra khi cháº¡y runtime).
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_data/              # Dá»¯ liá»‡u giáº£ láº­p Ä‘á»ƒ kiá»ƒm thá»­ nhanh.
â”‚       â”œâ”€â”€ long_conversation.jsonl  # Há»™i thoáº¡i dÃ i Ä‘á»ƒ test tÃ­nh nÄƒng Memory Trigger.
â”‚       â””â”€â”€ test_queries.md           # VÃ­ dá»¥ cÃ¢u há»i (mÆ¡ há»“ / rÃµ rÃ ng) Ä‘á»ƒ test pipeline.
â”‚
â”œâ”€â”€ requirements.txt            # Danh sÃ¡ch thÆ° viá»‡n Python cáº§n thiáº¿t.
â”œâ”€â”€ run_server.py               # (placeholder) local server script â€” khÃ´ng kÃ¨m Colab template.
â””â”€â”€ README.md                   # TÃ i liá»‡u hÆ°á»›ng dáº«n sá»­ dá»¥ng (File nÃ y).
â””â”€â”€ colab_server.ipynb          # Host model LLM (Llama-3)



```

### Chi tiáº¿t cÃ¡c module quan trá»ng trong `src/`:

- **`models.py`**: ÄÃ¢y lÃ  "xÆ°Æ¡ng sá»‘ng" cá»§a viá»‡c structured output. Thay vÃ¬ Ä‘á»ƒ LLM tráº£ vá» chuá»—i tá»± do, file nÃ y Ä‘á»‹nh nghÄ©a cÃ¡c class nhÆ° `SessionMemory`, `QueryAnalysis` giÃºp Ã©p kiá»ƒu dá»¯ liá»‡u tráº£ vá» thÃ nh JSON chuáº©n xÃ¡c.
- **`session_memory.py`**: Chá»©a hÃ m `check_and_summarize`. HÃ m nÃ y kiá»ƒm tra sá»‘ lÆ°á»£ng token hiá»‡n táº¡i so vá»›i `MEMORY_THRESHOLD_TOKENS`. Náº¿u vÆ°á»£t quÃ¡, nÃ³ gá»i LLM Ä‘á»ƒ tÃ³m táº¯t há»™i thoáº¡i cÅ© thÃ nh cáº¥u trÃºc JSON vÃ  lÆ°u láº¡i.
- **`query_processor.py`**: Thá»±c hiá»‡n chuá»—i xá»­ lÃ½:

1. Nháº­n cÃ¢u há»i ngÆ°á»i dÃ¹ng.
2. Káº¿t há»£p vá»›i ngá»¯ cáº£nh há»™i thoáº¡i gáº§n nháº¥t vÃ  bá»™ nhá»› session.
3. Há»i LLM: "CÃ¢u nÃ y cÃ³ mÆ¡ há»“ khÃ´ng? Náº¿u cÃ³ hÃ£y viáº¿t láº¡i".
4. Tráº£ vá» Ä‘á»‘i tÆ°á»£ng `QueryAnalysis` chá»©a cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c lÃ m rÃµ.

---

## âš ï¸ LÆ°u Ã½ & Giá»›i háº¡n

1. **Tá»‘c Ä‘á»™:** Do sá»­ dá»¥ng mÃ´ hÃ¬nh Llama-3-8B qua ngrok (tunneling), Ä‘á»™ trá»… (latency) cÃ³ thá»ƒ cao hÆ¡n so vá»›i gá»i API thÆ°Æ¡ng máº¡i trá»±c tiáº¿p (nhÆ° OpenAI).
2. **Context Window:** Demo sá»­ dá»¥ng giá»›i háº¡n context token an toÃ n (~2048 - 4096 tokens) Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»™ á»•n Ä‘á»‹nh trÃªn Colab.
3. **Dá»¯ liá»‡u:** Dá»¯ liá»‡u session Ä‘Æ°á»£c lÆ°u dÆ°á»›i dáº¡ng file JSON cá»¥c bá»™ trong thÆ° má»¥c `data/sessions/` Ä‘á»ƒ Ä‘Æ¡n giáº£n hÃ³a viá»‡c triá»ƒn khai (khÃ´ng setup Database riÃªng).
